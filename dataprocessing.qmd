---
title: "Carga y procesamiento de textos"
format: html
toc: true   
toc-title: "√çndice"       
toc-depth: 4              # Por alguna raz√≥n no muestra t√≠tulos de nivel 4. Revisarlo
code-copy: true
editor: visual
---

## üì¶Preparando los paquetes

Para seguir este tutorial por primera vez, deber√°s instalar una serie de paquetes[^1] que emplearemos: `quanteda`, `readtext`, `dplyr` y `stringr`. Esto se hace a trav√©s del comando: `install.packages()`:

[^1]:
    ::: {.callout-tip appearance="simple"}
    `R` es un lenguaje de programaci√≥n abierto y colaborativo que sigue una estructura totalmente descentralizada. Cuando instalamos `R` por primera vez, s√≥lo instalamos sus funcionalidades b√°sicas. Todas aquellas funcionalidades adicionales llevadas a cabo por terceras personas deben instalarse en lo que se denominan **paquetes** o **libraries** en ingl√©s.

    Cada vez que vayas a emplear un paquete, debes cargarlo, por defecto, cada vez que abres `R` estos paquetes no est√°n cargados.
    :::

```{r, eval = FALSE}
install.packages(c("quanteda", "readtext", "dplyr", "stringi", "quanteda.textplots", "ggplot2", "stringr", "tm", "topicmodels"))
```

#### ¬øPara qu√© sirve cada uno?

| **Paquete**                                                                                         | **Descripci√≥n**                                                                                                                                              |
|---------------------------|---------------------------------------------|
| [**`quanteda`**](https://quanteda.io/)                                                              | Paquete de an√°lisis de textos, incluyendo tokenizaci√≥n, conteo y limpieza de textos                                                                          |
| [**`readtext`**](https://cran.r-project.org/web/packages/readtext/vignettes/readtext_vignette.html) | Permite importar archivos de texto en varios formatos, facilitando la carga de datos                                                                         |
| [**`dplyr`**](https://dplyr.tidyverse.org/)                                                         | Herramienta para manipulaci√≥n y transformaci√≥n de datos, √∫til para filtrar y organizar datos                                                                 |
| [**`stringi`**](https://stringi.gagolewski.com/)                                                    | Conjunto de funciones para trabajar con texto, especialmente √∫til para limpieza y manejo de expresiones regulares[^2]                                        |
| [**`quanteda.textplots`**](https://quanteda.io/reference/textplots.html)                            | Extensi√≥n de `quanteda` para crear visualizaciones como nubes de palabras y gr√°ficos de dispersi√≥n l√©xica.                                                   |
| [**`ggplot2`**](https://ggplot2.tidyverse.org/)                                                     | Paquete de visualizaci√≥n de datos que permite crear gr√°ficos personalizados y atractivos.                                                                    |
| [**`stringr`**](https://stringr.tidyverse.org/)                                                     | Facilita la manipulaci√≥n de cadenas de texto con funciones simples y potentes, parte del `tidyverse`.                                                        |
| [**`tm`**](https://tm.r-forge.r-project.org/)                                                       | Paquete cl√°sico para el an√°lisis de texto y miner√≠a de textos, incluye herramientas para el procesamiento de textos y la creaci√≥n de matrices de documentos. |
| [**`topicmodels`**](https://rbasics.org/packages/topicmodels-package-in-r/)                         | Se utiliza para el modelado de temas latentes, permitiendo ajustar modelos como LDA para identificar patrones tem√°ticos.                                     |

[^2]:
    ::: {.callout-tip appearance="simple"}
    Una **expresi√≥n regular** es un patr√≥n de b√∫squeda utilizado para manipular texto espec√≠fico en una cadena. Facilita tareas como eliminar caracteres no deseados o extraer informaci√≥n espec√≠fica (e.g., fechas o n√∫meros). Es especialmente √∫til en la limpieza y preprocesamiento de datos textuales.
    :::

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
La **tokenizaci√≥n** es el proceso de dividir un texto en unidades m√°s peque√±as llamdas *tokens*. Estas unidades pueden ser palabras, s√≠mbolos, frases o incluso caracteres dependiendo del tipo de an√°lisis que se vaya a realizar. En `quanteda` consideramos la palabra como la unidad m√≠nima de trabajo. Imag√≠nate que tienes la siguiente oraci√≥n:

"Hola, ¬øc√≥mo est√°s?"

La tokenizaci√≥n de esta frase podr√≠a dar como resultado los siguientes tokens: "Hola", "¬ø", "c√≥mo", "est√°s", "?"

Esto es especialmente √∫til cuando estamos trabajando con estudios relacionados con frecuencias de palabras.
:::

## üìÑ‚û°Ô∏èüñ•Ô∏èImportaci√≥n de datos de texto

Vamos a vincular el archivo de¬†texto en la aplicaci√≥n de RStudios. Para ello vamos a cargar los paquetes que hemos instalado anteriormente¬†con el comando `library("name")`

```{r, eval=T}
library(quanteda)
library(readtext)
library(dplyr)
library(stringi)
```

Es importante resaltar que, si no llamamos antes el paquete, los comandos que introduzcamos despu√©s no funcionar√°n o nos dar√°n error. Aseg√∫rate de cargar siempre la librer√≠a antes de empezar a trabajar.

Una vez cargados, el programa estar√° listo para leer nuestro archivo de texto. La formula que vamos a escribir para decirle a `quanteda` que archivo analizar ser√° el siguiente:

```{r, eval=T}
navalny_raw <- as.character(readtext("NAVALNY.txt"))
```

**‚ùóATENCI√ìN:** Si por alguna raz√≥n hiciesemos alg√∫n cambio en el contenido del archivo, deberemos de aplicar el paso anterior de nuevo. Cuando cargamos un archivo en R, se guarda una copia y cualquier cambio en el original no se refleja autom√°ticamente.

**ü§î¬øQu√© hemos hecho?**

Este comando carga el archivo `NAVALNY.txt` en el objeto `navalny_raw`, el cual contiene el contenido del texto. Vamos a desgranar este prompt para que pueda entenderse m√°s facil:

-   `navalny_raw` es un objeto en R que almacena el texto como una cadena de caracteres (character vector). En `R` hablamos de **objetos** para referirnos a los contenedores donde almacenamos datos e informaci√≥n. En el caso anterior, el objeto `data_char_navalny` almacena el texto plano que vamos a utilizar. Existen distintos objetos con diferentes datos almacenados: matrices, n√∫meros, listas jerarquizadas, as√≠ como un sin fin de combinaciones. A lo largo de este caso pr√°ctico trabajaremos con ellos para gestionar m√°s facilmente el an√°lisis cuantitativo.

-   `<-` emula a una flecha y b√°sicamente indica la direcci√≥n de la acci√≥n. Al objeto `navalny_raw` estamos aplic√°ndole una funci√≥n

-   `as.character()`: Se trata de la funci√≥n que estamos aplicando. Esta funci√≥n convierte todo lo que se contiene dentro de ella en car√°cter. En `R` toda funci√≥n viene seguida por unos par√©ntesis dentro de los cu√°les se incluyen los par√°metros de dicha funci√≥n. Si no hay contenido, se aplican los par√°metros que la funci√≥n trae por defecto.

-   `readtext`: Aqu√≠ estamos empleando una funci√≥n expec√≠fica del paquete `readtext`. Si no hubi√©semos cargado el paquete anteriormente, podr√≠amos invocarlo espec√≠ficamente para activar esta funci√≥n con la notaci√≥n `paquete::funci√≥n`. Aqu√≠, lo que le estamos diciendo a RStudio es que, del paquete `readtext`, aplique espec√≠ficamente la funci√≥n lectura que casualmente tambi√©n se llama `readtext` . Dentro indicamos entrecomillada la ruta del archivo a importar. Un **problema muy com√∫n** que puede surgir a la hora de introducir la URL de la ubicaci√≥n del archivo es expresarlo con barras laterales izquierdas " \\ ", tal y como viene en la barra de direcci√≥n del explorador de archivos de Windows, en vez de la derecha" / ". Si tienes problemas leer tu .txt ¬°prueba con hacer este cambio!

-   `names(navalny_raw) <- "navalny"`: Asigna un nombre al objeto que contiene el texto, facilitando su identificaci√≥n en futuros an√°lisis.

#### üîç Comprobaciones

En el an√°lisis cuantitativo toda precauci√≥n es poca. Vamos a verificar que el texto ha sido le√≠do por el programa. Usaremos el paquete `stringi` para ver los primeros 75 caracteres de nuestro archivo y confirmar que los datos se cargaron bien.

```{R, eval=T}

# Comprobar los primeros 75 caracteres del texto
stri_sub(navalny_raw, 1, 75)
```

Si hemos hecho los pasos bien, tendr√©is que haber recibir este texto de vuelta:

```         
[1] "2022\nJanuary 17th\nExactly one year ago today I came home, to Russia.\nI didn"
```

## üóÉÔ∏èAcotando el texto a analizar

Nuestro siguiente objetivo es seleccionar qu√© partes del texto vamos aplicar el an√°lisis cuantitativo. Puede que nuestro foco de inter√©s sea algun apartado concreto de nuestro material, por lo que vamos a crear un objeto que albergue un rango determinado dentro de nuestro fichero `txt` . Con esto, nos quitaremos toda la informaci√≥n innecesaria que puede ensuciar nuestros resultados.

El proceso que vamos a realizar a continuaci√≥n es muy √∫til cuando los archivos que manejamos tienen ligados metadatos. Normalmente, esta metadata suele ser m√°s un dolor de cabeza que otra cosa y es recomendable realizar una limpieza previa para que esos datos no se mezclen con el contenido de nuestro an√°lisis. En este apartado seguiremos trabajando con el paquete `stringi`.

Si el texto contiene secciones que no necesitamos para el an√°lisis, podemos filtrarlas o limpiarlas en esta etapa.

#### PASO 1: Identificaci√≥n de comienzo y fin del texto

Para crear el objeto que albergue el rango de texto a analizar deberemos empezar indicando donde empieza y termina nuestra selecci√≥n. Imaginemos que s√≥lo nos interesa analizar los √∫ltimos a√±os de vida de Navalny. Para ello, crearemos dos valores de posici√≥n: `start_v` y `end_v`, donde `start_` ser√°: "2023, January 12th" y `end_v` "Alexei Navalny died".

Localizado el rango que queremos, la forma de expresarlo en el programa ser√≠a el siguiente:

```{r, eval=T}
(start_v <- stri_locate_first_fixed(navalny_raw, "2023\nJanuary 12th")[1])
```

```{r, eval=T}
(end_v <- stri_locate_last_fixed(navalny_raw, "Alexei Navalny died")[1])
```

Si lo hemos aplicado bien, la funci√≥n deber√≠a de devolver los siguientes resultados

-   Para `start_value`

    ```         
    [1] 23654
    ```

<!-- -->

-   Para `end_value`

    ```         
    [1] 44099
    ```

**ü§î¬øQu√© hemos hecho?**

-   Tanto `start_v` como `end_v` son nombres que hemos asignado a la posici√≥n espec√≠ficas del texto. En s√≠, no significan nada. Solo decimos, a trav√©s de "\<-" que dichos nombres albergan una funci√≥n de posicionamiento.

-   Las funciones del paquete `stringi`: `stri_locate_first_fixed` y `stri_locate_last_fixed` buscan y encuentran la primera coincidencia del valor entrecomillado que precede a nuestro objeto `data_char_NALVANY`

-   El \[1\] es un indicador que le estamos dando a la funci√≥n para que escoja la primera posici√≥n donde aparezca el texto que hayamos escogido.

-   As√≠, cuando vemos devuelto las respuestas `[1] 23653` y `[1] 44141` quiere decir que para `start_v` y `end_v` est√° asignado el primer valor donde aparece dichas expresiones , localizadas por primera vez en la posici√≥n 23653 y 44141 de nuestro texto.

#### PASO 2: Nuevo objeto

Creado nuestro punto de inicio y final de nuestra zona de trabajo, haremos un objeto que alberge dicho rango. Lo llamaremos: `navalny_fix`

```{r, eval=T}
navalny_fix <- stri_sub(navalny_raw, start_v, end_v)
length(navalny_fix)
```

Al iniciar el c√≥digo el valor que os ha tenido que recuperar, adem√°s de almacenar el objeto en la pesta√±a `Environment` de RStuido, es:

```         
[1] 1
```

**ü§î¬øQu√© hemos hecho?**

-   `navalny_fix` es el nombre del objeto que almacena la funci√≥n que ha sido asignada. En este caso, a trav√©s de `stri_sub`, estamos extrayendo una parte del texto `navalny_fix` . A diferencia del caso anterior, aqu√≠ le estamos pidiendo que, en vez de que recuper un n√∫mero detemrinado de caracteres, escoja todos los que hay comprendidos entre las posiciones que hemos dado a `start_v` y a `end_v`. Con esto nos aseguramos que el objeto `navalny_fix` siempre trabaje en los rangos que nos interesa analizar.

-   `length(navalny_fix)` es una expresi√≥n que usamos para comprobar cuandos valores existen en nuestro objeto. Es una forma de asegurarnos de que nuestro objeto solo tiene un vector y no es un conjunto de fragmentos de texto. Por eso, al introducirlo, el programa nos devuelve el valor 1 porque solo hay 1 valor dentro de nuestro objeto.

## üóëÔ∏è Limpiando datos

::: {.callout-caution appearance="simple"}
El fichero de texto con el que estamos trabajando ya est√° libre de ruido, por lo que continuaremos el resto del ejemplo trabajando con el objeto `navalny_raw`.
:::

Ya tenemos nuestro set de datos, nos toca empezar a limpiar antes de tokenizar y empezar a analizar.

#### PASO 1: Comprobar la estructura del texto

Vamos a abrir un momento nuestro archivo para ver lo que contiene. Aqu√≠ te ense√±o las primeras l√≠neas:

```{r, echo= FALSE}
# Convertir el texto en un vector de l√≠neas
lines <- unlist(strsplit(navalny_raw, "\n"))

# Mostrar las primeras 20 l√≠neas del texto en formato raw
cat(lines[1:15], sep = "\n")

```

Aqu√≠ queda m√°s clara la estructura del texto:

-   Cada entrada del diario empieza con el a√±o en la primera l√≠nea

-   Dentro de cada a√±o, se dividen por d√≠as las entradas

-   Los p√°rrafos est√°n separados por saltos de l√≠nea

-   Las entradas est√°n separadas entre s√≠ tambi√©n por una linea en blanco.

A continuaci√≥n lo que vamos a hacer es crear un objeto lista[^3], en la que cada elemento ser√° una entrada del diario.

[^3]:
    ::: {.callout-tip appearance="simple"}
    Una **lista** es una estructura de datos que puede contener elementos de diferentes tipos (num√©rico, caract√©res, vectores o incluso otras listas) en un solo objeto. Cada elemento en una lista se puede acceder de forma individual usando √≠ndices. Esto se hace utilizando corchetes dobles. Por ejemplo si queremos ver el segundo elemento de la lista `lista`, lo indicaremos as√≠: `lista[[2]]`.
    :::

#### PASO 2: Conversi√≥n del texto en vectores

Ahora que comprendemos la estructura, vamos a separar el texto en entradas diarias. Primero dividimos el texto en l√≠neas, donde cada l√≠nea se convierte en un elemento de un vector. Esto nos permite identificar las l√≠neas que contienen fechas y separar las entradas.

```{r}
# Convertir el texto en un vector de l√≠neas
lines <- unlist(strsplit(navalny_raw, '\n')) # \n indica un salto de l√≠nea
```

**ü§î¬øQu√© hemos hecho?**

-   `strsplit()` divide el texto por saltos de l√≠nea (`"\n"`), creando un vector en el que cada l√≠nea es un elemento independiente.

-   Usamos `unlist()` para simplificar la estructura y trabajar con un vector plano.

```{r}
head(lines) # Veamos las primeras seis l√≠neas de nuestro objeto
```

#### PASO 3: Creaci√≥n de √≠ndices para identificar entradas

En este paso, vamos a crear los **√≠ndices** que nos permitir√°n identificar las l√≠neas en el texto que corresponden a cada a√±o y a cada d√≠a. Esto nos ayudar√° a estructurar las entradas en el pr√≥ximo paso.

1.  Utilizando [expresiones regulares](https://es.wikipedia.org/wiki/Expresi%C3%B3n_regular), vamos a identificar las l√≠neas que contengan s√≥lo el a√±o. Estas l√≠neas marcan el inicio de cada conjunto de entradas anuales

```{r}

year_indices <- grep("^\\d{4}$", lines)

print(year_indices) # Muestra las l√≠neas que contienen el a√±o
```

2.  Hemos identificado tres l√≠neas que incluyen el a√±o. Ahora haremos lo mismo para las l√≠neas que encuentren el mes y el d√≠a

```{r}

day_indices <- grep("^(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2}(st|nd|rd|th)?$", lines)

length(day_indices) # N√∫mero de entradas identificadas

```

**ü§î¬øQu√© hemos hecho?**

-   `year_indices` contiene los √≠ndices de las l√≠neas con los a√±os, es decir, las posiciones donde comienza cada a√±o en el texto. La expresi√≥n regular `^\\d{4}` busca cuatro d√≠gitos al inicio de la l√≠nea.

-   `month_day_indices` contiene los √≠ndices de las l√≠neas con fechas diarias, indicando el inicio de cada d√≠a dentro de los a√±os.

    -   `(January|February|...)`: Busca un mes escrito en ingl√©s.

    -   `\\s+`: Representa uno o m√°s espacios.

    -   `\\d{1,2}(st|nd|rd|th)?$`: Busca el d√≠a, que tendr√° uno o dos d√≠gitos y que puede ir seguido de "st", "nd", "rd", o "th" al final de la l√≠nea.

#### PASO 4: Creaci√≥n de entradas del diario

Ahora que tenemos los √≠ndices para los a√±os y d√≠as, podemos organizar el texto en **entradas anidadas**: cada a√±o ser√° un grupo principal, y dentro de cada a√±o, cada d√≠a ser√° una entrada individual.

El siguiente c√≥digo es un poco tocho, te intento explicar:

1.  Creamos las entradas por a√±o. Para esto utilizamos el objeto `year_indices` que construimos antes.
2.  Creamos sublistas dentro de cada a√±o con nuestro objeto `month_day_indices`.

```{r}
# Dividimos el texto en entradas anidadas (por a√±o y d√≠a)
yearly_entries <- lapply(
  seq_along(year_indices), 
  function(i) {
    start_year <- year_indices[i]
    end_year <- if (i < length(year_indices))
      year_indices[i + 1] - 1
    else
      length(lines)
    
    # Extraemos las l√≠neas correspondientes al a√±o actual
    year_lines <- lines[start_year:end_year]
    
    # Encontrar las entradas diarias dentro del a√±o actual
    day_indices <- grep(
      "^(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2}(st|nd|rd|th)?$",
      year_lines
      )
    
    # Crear una sublista para cada d√≠a dentro del a√±o
    entries <- lapply(seq_along(day_indices), function(j) {
      start_day <- day_indices[j]
      end_day <- if (j < length(day_indices))
        day_indices[j + 1] - 1
      else
        length(year_lines)
      year_lines[start_day:end_day]
      })
  
  # Devolver una lista con el a√±o y sus entradas diarias
  list(year = year_lines[1], entries = entries)
})

```

**ü§î¬øQu√© hemos hecho?**

-   Cada elemento en `yearly_entries` es un a√±o completo

    ```{r}
    print(yearly_entries[[1]]$year) # primer a√±o
    ```

-   Dentro de cada a√±o, `entries` contiene las entradas diarias como sublistas, donde cada d√≠a es un vector de p√°rrafos

    ```{r}
    length(yearly_entries[[1]]$entries)
    ```

Para ello, hemos combinado diferentes funciones en un s√≥lo script:

-   `lapply()` sirve para aplicar una funci√≥n a cada elemento de un vector o lista. En nuestro caso, itera sobre cada √≠ndice de `year_indices`, procesando el texto correspondiente a cada √±o. Genera una lista `yearly_indices`donde cada elemento representa un a√±o y sus entradas diarias. La segunda vez que la empleo es para crear sublistas para cada d√≠a dentro del a√±o, aplic√°ndola sobre `day_indices`.

-   `seq_along()` genera una secuencia de n√∫meros que corresponden a la longitud de un vector o lista. Lo utilizo para generar una secuencia de √≠ndices a iterar sobre los a√±os y sobre los d√≠as dentro de cada a√±o.

-   `grep()` busca patrones espec√≠ficos dentro de un vector, tal y como hicimos antes.

-   `if`dentro de `lapply()`define los l√≠mites de inicio y fin de cada a√±o.

-   `list()` crea la lista que almacena todas las entradas.

## üóø ¬°A la tokenizaci√≥n!

Ya tenemos nuestro texto bien organizado y estructurado. Toca dividir a√∫n m√°s y limpiar. Para ello vamos a hacer lo siguiente:

1.  Convertimos el texto en min√∫sculas y eliminamos los signos de puntuaci√≥n
2.  Tokenizamos el texto dividi√©ndolo en palabras. De manera que nuestra unidad de an√°lisis ser√° la palabra[^4].
3.  Eliminamos todas las palabras vac√≠as[^5] para quedarnos s√≥lo con aquellas relevantes para nuestro an√°lisis.

[^4]:
    ::: {.callout-tip appearance="simple"}
    Aqu√≠ es importante diferenciar entre an√°lisis textual y un an√°lisis sem√°ntico. En el an√°lisis de textos examinamos cuestiones como la frecuencia de las palabras, patrones o estructura, sin considerar el significado de cada palabra. Se tratar√≠a de un paso previo al an√°lisis sem√°ntico donde nos centramos en el significado y el contexto de las palabras.
    :::

[^5]:
    ::: {.callout-tip appearance="simple"}
    Las **palabras vac√≠as** son t√©rminos comunes (como "el", "de", "y") que suelen aparecer con mucha frecuencia en el texto, pero aportan poco significado o valor informativo al an√°lisis. Estas palabras se eliminan generalmente para centrar el an√°lisis en los t√©rminos m√°s relevantes.
    :::

#### PASO 1: Texto en min√∫scula y puntuaci√≥n fuera

Para asegurarnos que palabras id√©nticas no se traten como diferentes por su formato, converitmos todo el texto a min√∫sculas y eliminamos puntuaci√≥n.

```{r}
# Convertir cada entrada diaria a min√∫sculas y eliminar signos de puntuaci√≥n
yearly_entries <- lapply(yearly_entries, function(year) {
  year$entries <- lapply(year$entries, function(entry) {
    # Convertir el texto a min√∫sculas y eliminar puntuaci√≥n
    entry <- char_tolower(entry)
    entry <- gsub("[[:punct:]]", "", entry)
    entry
  })
  year  # Devolver la lista de a√±o modificada
})

```

**ü§î¬øQu√© hemos hecho?**

-   La funci√≥n `char_tolower()` convierte el texto en min√∫sculas.

-   La funci√≥n `gsub()` sustituye un patr√≥n de texto por otro. En nuestro caso, le hemos pedido que busque cualquier signo de puntuaci√≥n empleando la expresi√≥n regular `[[:punct:]]` y la reemplace por nada.

-   Despu√©s hemos pedido que incluya estos cambios nuevamente en nuestro objeto `yearly_entries`.

Si observas las primeras l√≠neas de una entrada, ver√°s que todo ha funcionado tal y como esper√°bamos:

```{r, echo=FALSE}

# Aqu√≠ podemos ver qu√© ha pasado con las primeras 5 l√≠neas de la primera entrada
print(head(yearly_entries[[1]]$entries[[1]], 5))

```

#### PASO 2: Tokenizaci√≥n

Para que el programa pueda analizar y realizar manipulaciones sobre las palabras de forma individualizada, vamos a convertir a cada una de ellas en peque√±os valores que llamamos **tokens.**

```{r}
# Tokenizar cada entrada diaria dentro de cada a√±o
yearly_entries <- lapply(yearly_entries, function(year) {
  year$entries <- lapply(year$entries, function(entry) {
    tokens(entry, what = "word")
  })
  year  # Devolver la lista de a√±o modificada
})

```

**ü§î¬øQu√© hemos hecho?**

-   Siguiendo la misma estructura de la vez anterior, hemos incorporado la funci√≥n `tokens()` y lo hemos aplicado al objeto `entry`

-   Adem√°s, hemos utilizado el par√°metro `what=` en el que indicamos el nivel. En nuestro caso tokenizamos por palabras. Otras opciones son por caracteres (`character`) y frases (`sentence`).

Ahora en lugar de contener un listado de filas por entrada, lo que tengo es una bolsa de palabras:

```{r, echo=FALSE}
print(head(yearly_entries[[1]]$entries[[1]], 3)) 
```

#### PASO 3: Eliminaci√≥n de palabras vac√≠as

Para centrarnos en las palabras significativas, eliminamos las **palabras vac√≠as** (stopwords), que suelen ser t√©rminos comunes y poco informativos, como "el", "de", "y". Esto permite que el an√°lisis se centre en t√©rminos con m√°s contenido sem√°ntico.

```{r}
# Eliminar palabras vac√≠as en ingl√©s en cada entrada diaria
yearly_entries <- lapply(yearly_entries, function(year) {
  year$entries <- lapply(year$entries, function(entry) {
    tokens_remove(entry, pattern = stopwords("en")) 
  })
  year  # Devolver la lista de a√±o modificada
})

```

**ü§î¬øQu√© hemos hecho?**

-   Aqu√≠ empleamos la funci√≥n `tokens_remove()` otra vez aplicada al objeto `entry`, en este caso empleamos el par√°metro `pattern =` para indicar que eliminaremos los tokens que representen palabras vac√≠as, en par√©ntesis incluimos la lengua a trav√©s de su c√≥digo ISO, en nuestro caso el ingl√©s. [Aqu√≠ tienes el listado completo de idiomas](https://www.rdocumentation.org/packages/stopwords/versions/2.3). El paquete `stopwords` permite asimismo crear y/o a√±adir tus propias palabras vac√≠as.

F√≠jate c√≥mo, en comparaci√≥n con el fragmento anterior, se han eliminado palabras como "in", "my" u "only".

```{r, echo=FALSE}
print(head(yearly_entries[[1]]$entries[[1]], 3))
```

::: {.callout-important appearance="simple"}
Como habr√°s notado, es posible juntar todos estos pasos en uno s√≥lo. Aqu√≠ lo mostramos por trozos para que vayas comprendiendo el proceso, pero podr√≠amos hacer todo esto de una vez.
:::

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
En ingl√©s, es posible que el texto venga acompa√±ado de ap√≥strofes como en los casos de `don't` y `he's`. Aqu√≠, `quanteda` no tomar√° las `'t` ni las `'s` como elementos aislados, sino que lo mantendr√° unida a la palabra para respetar el significado original.
:::
