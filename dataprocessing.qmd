---
title: "Carga y procesamiento de textos"
format: html
toc: true   
toc-title: "√çndice"       
toc-depth: 4              # Por alguna raz√≥n no muestra t√≠tulos de nivel 4. Revisarlo
code-copy: true
editor: visual
---

## üì¶Preparando los paquetes

Antes de comenzar el an√°lisis es obligatorio instalar dos paquetes b√°sicos: `quanteda` y `readtext` a trav√©s del comando: `install.packages(")` . En primer lugar, para poder instalar `quanteda` , as√≠ como cualquier otro paquete en R, deberemos de de introducir en la consola el comando:

```{r, eval = FALSE}
install.packages("quanteda")
```

La misma f√≥rmula aplicaremos para el paquete `readtext`

```{r, eval = FALSE}
install.packages("readtext")
```

#### ¬øPor qu√© lo usamos?

-   `quanteda` es la herramienta que nos va a proporcionar los recursos para hacer un an√°lisis cuantitativo de un texto, incluyendo la tokenizaci√≥n^\[1\]^, la creaci√≥n de matrices de t√©rminos y el an√°lisis de frecuencia.

-   `readtext` se utiliza para cargar y leer datos textuales desde diferentes formatos (como archivos de texto, documentos de Word, etc.). Para evitar dolores de cabeza, nosotros recomendamos que el material que se vaya a trabajar est√© en un formato plano .txt. Los formatos anteriores pueden dar problemas por la forma en que se estructuran los datos y los elementos adicionales que suelen contener, lo que requiere aplicar procesos adicionales de limpieza que puede alargar nuestro an√°lisis.

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[1\]~^ En `quanteda` hablamos de **tokenizaci√≥n** para referirnos a la unidad m√≠nima de trabajo.

Imaginate que tienes la siguiente oraci√≥n:

"Hola, ¬øc√≥mo est√°s?"

La tokenizaci√≥n de esta frase podr√≠a dar como resultado los siguientes tokens: "Hola", "¬ø", "c√≥mo", "est√°s", "?"

Esto es especialmente √∫til cuando estamos trabajando con estudios relacionados con frecuencias de palabras.
:::

## üìÑ‚û°Ô∏èüñ•Ô∏èVolcando los archivos de texto a RStudio

Vamos a vincular el archivo de¬†texto en la aplicaci√≥n de RStudios. Para ello vamos a aplicar los dos paquetes que hemos instalado anteriormente¬†con el comando `library("name")`

```{r, eval=FALSE}
library("quanteda")
library("readtext")
```

Es importante resaltar que, si no llamamos antes el paquete, los comandos que introduzcamos despu√©s no funcionar√°n o nos dar√°n error. Aseg√∫rate de cargar siempre la librer√≠a antes de empezar a trabajar.

Una vez cargados, el programa estar√° listo para leer nuestro archivo de texto. La formula que vamos a escribir para decirle a `quanteda` que archivo analizar ser√° el siguiente:

```{r, eval=FALSE}
data_char_NALVANY <- as.character(readtext::readtext("G:/Mi unidad/Yo sigo/NALVANY.txt"))
names(data_char_NALVANY) <- "NALVANY"
```

**‚ùóATENICI√ìN:** Si por alguna raz√≥n hiciesemos alg√∫n cambio en el contenido del archivo, deberemos de aplicar el paso anterior de nuevo. Cuando cargamos un archivo en R, se guarda una copia y cualquier cambio en el original no se refleja autom√°ticamente.

#### ü§î¬øQu√© significa esta funci√≥n?

Vamos a desgranar este prompt para que pueda entenderse m√°s facil:

-   `data_char_"TEXTO"`: La variable data_char_NALVANY es un objeto^\[2\]^ en R que almacena el texto como una cadena de caracteres (character vector).

-   `as.character()`: Convierte el objeto cargado en un formato de texto sencillo, que es m√°s f√°cil de manejar para el an√°lisis.

-   `readtext::readtext`: Como v√©is, se ha utilizado una expresi√≥n doble del paquete `readtext`. Esto proviene de la notaci√≥n `paquete::funci√≥n` y se hace cuando queremos asegurarnos de utilizar una funci√≥n espec√≠fica. Aqu√≠, lo que le estamos diciendo a RStudios es que, del paquete `readtext`, aplique espec√≠ficamente la funci√≥n lectura que casualmente tambi√©n se llama `readtext`

    -   Un **problema muy com√∫n** que puede surgir a la hora de introducir la URL de la ubicaci√≥n del archivo es expresarlo con barras laterales izquierdas " \\ ", tal y como viene en la barra de direcci√≥n del explorador de archivos de Windows, en vez de la derecha " / ". Si tienes problemas leer tu .txt ¬°prueba con hacer este cambio!

-   `names(data_char_NALVANY) <- "Nalvany"`: Asigna un nombre al objeto que contiene el texto, facilitando su identificaci√≥n en futuros an√°lisis.

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[2\]~^ En `R` hablamos de **objetos** para referirnos a los contenedores donde almacenamos datos e informaci√≥n. En el caso anterior, el objeto `data_char_NALVANY` almacena el texto plano que vamos a utilizar.

Existen distintos objetos con diferentes datos almacenados: matrices, n√∫meros, listas jerarquizadas, as√≠ como un sin fin de combinaciones. A lo largo de este caso pr√°ctico trabajaremos con ellos para gestionar m√°s facilmente el an√°lisis cuantitativo.
:::

#### üîç Comprobaciones

En el an√°lisis cuantitativo toda precauci√≥n es poca , as√≠ que vamos a realizar una serie de comprobaciones para verificar que el texto ha sido leido por el programa. Para ello, vamos a pedirle a RStudio que nos devuelva los primeros 75 caracteres de nuestro archivo NALVANY.txt mediante el paquete: `stringi`.

```{R, eval=FALSE}
library.("stringi") #Primero llamamos al paquete
stri_sub(data_char_NALVANY, 1, 75) #Aplicamos la funci√≥n para que nos devuelva los caracteres situados entre la posici√≥n 1 y 75.
```

Si hemos hecho los pasos bien, tendr√©is que haber recibir este texto de vuelta:

```         
[1] "2022\nJanuary 17th\nExactly one year ago today I came home, to Russia.\nI didn"
```

## üóÉÔ∏èAcotando nuestro espacio de trabajo

Nuestro siguiente objetivo es seleccionar qu√© partes del texto vamos aplicar el an√°lisis cuantitativo. Puede que nuestro foco de inter√©s sea algun apartado concreto de nuestro material, por lo que vamos a crear un objeto que albergue un rango determinado dentro de nuestro "".txt . Con esto nos quitaremos toda la informaci√≥n innecesaria que puede ensuciar nuestros resultados.

El proceso que vamos a realizar a continuaci√≥n es muy √∫til cuando los archivos que manejamos tienen ligados metadatos. Normalmente, esta metadata suele ser m√°s un dolor de cabeza que otra cosa y es recomendable realizar una limpieza previa para que esos datos no se mezclen con el contenido de nuestro an√°lisis.

En este apartado seguiremos trabajando con el paquete `stringi` ^\[3\]^

#### PASO 1: Asignaci√≥n de los rangos del texto

Para crear el objeto que albergue el rango de texto a analizar deberemos empezar indicando donde empieza y termina nuestra selecci√≥n. Para ello, crearemos dos valores de posici√≥n: `start_v` y `end_v`, donde `start_` ser√°: "2023, January 12th" y `end_v` "FIN".

Localizado el rango que queremos, la forma de expresarlo en el programa ser√≠a el siguiente:

```{r, eval=FALSE}
(start_v <- stri_locate_first_fixed(data_char_NALVANY, "2023\nJanuary 12th")[1])
```

```{r, eval=FALSE}
(end_v <- stri_locate_last_fixed(data_char_NALVANY, "FIN")[1])
```

Si lo hemos aplicado bien, la funci√≥n deber√≠a de devolver los siguientes resultados

-   Para `start_value`

    ```         
    [1] 23653
    ```

<!-- -->

-   Para `end_value`

    ```         
    [1] 44141
    ```

#### ü§î¬øQu√© significa esta expresi√≥n?

-   Tanto `start_v` como `end_v` son nombres que hemos asignado a la posici√≥n espec√≠ficas del texto. En s√≠, no significan nada. Solo decimos, a trav√©s de "\<- " que dichos nombres albergan una funci√≥n de posicionamiento.

-   Las funciones del paquete `stringi`: `stri_locate_first_fixed` y `stri_locate_last_fixed` buscan y encuentran la primera coincidencia del valor entrecomillado que precede a nuestro objeto `data_char_NALVANY`

-   El \[1\] es un indicador que le estamos dando a la funci√≥n para que escoja la primera posici√≥n donde aparezca el texto que hayamos escogido.

-   As√≠, cuando vemos devuelto las respuestas `[1] 23653` y `[1] 44141` quiere decir que para `start_v` y `end_v` est√° asignado el primer valor donde aparece dichas expresiones , localizadas por primera vez en la posici√≥n 23653 y 44141 de nuestro texto.

#### PASO 2, creando nuestro objeto

Creado nuestro punto de inicio y final de nuestra zona de trabajo, haremos un objeto que alberge dicho rango. Lo llamaremos: `diary_v`

```{r, eval=FALSE}
diary_v <- stri_sub(data_char_NALVANY, start_v, end_v)
length(diary_v)
```

Al iniciar el c√≥digo el valor que os ha tenido que recuperar, adem√°s de almacenar el objeto en la pesta√±a `Environment` de RStuido, es:

```         
[1] 1
```

#### ü§î¬øQu√© significa esta expresi√≥n?

-   `diary_v` es el nombre del objeto que almacena la funci√≥n que ha sido asignada. En este caso, a trav√©s de `stri_sub`, estamos extrayendo una parte del texto `data_char_NALVANY` . A diferencia del caso anterior, aqu√≠ le estamos pidiendo que, en vez de que recuper un n√∫mero detemrinado de caracteres, escoja todos los que hay comprendidos entre las posiciones que hemos dado a `start_v` y a `end_v`. Con esto nos aseguramos que el objeto `diary_v` siempre trabaje en los rangos que nos interesa analizar.

-   `legth(diary_v)` es una expresi√≥n que usamos para comprobar cuandos valores existen en nuestro objeto. Es una forma de asegurarnos de que nuestro objeto solo tiene un vector y no es un conjunto de fragmentos de texto. Por eso, al introducirlo, el programa nos devuelve el valor 1 porque solo hay 1 valor dentro de nuestro objeto.

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[3\]~^ El paquete `stringi` es una herramienta muy versatil para el manejo y procesamiento de cadenas de texto. Hemos visto como puede hacer b√∫squedas de posicionamiento, pero tambi√©n puede servir para realizar operciones relacionadas con la manipulaci√≥n de texto: ya sea para remplazar partes del mismo, verificar un formato o pasar de un c√≥digo a otro.
:::

## üóø ¬°A la tokenizaci√≥n!

Realizada la limpieza de datos, es hora de preparar nuestro material para convertirlo en un objeto analizable. Para ello haremos tres cosas:

1.  Convertiremos todo el texto almacenado en `diary_v` en tokens.
2.  Pasaremos toda la informaci√≥n a min√∫sculas mediante la funci√≥n `tolower()`
3.  Eliminaremos los signos de puntuaci√≥n con la funci√≥n `remove_punct=TRUE`

#### PASO 1: tokenizaci√≥n

Para que el programa pueda analizar y realizar manipulaciones sobre las palabras de forma individualizada, vamos a convertir a cada una de ellas en peque√±os valores que llamamos **tokens.**

La funci√≥n `tokens()` del paquete `quanteda` es el que nos ayudar√° a realizar este trabajo.

```{r, eval=FALSE}
diary_v_toks <- tokens(diary_v)
```

#### **ü§î¬øQu√© significa esta expresi√≥n?**

Hemos creado un nuevo objeto: `diary_v_toks` donde los valores que tiene asignado han sido convertidos en una unidad manipulable llamado **token**. Esto nos permitir√° poder realizar los dos pasos siguientes.

#### PASO 2: eliminaci√≥n de las may√∫sculas.

R es sensible a las may√∫sculas y las toma como valor diferente a como ser√≠a en min√∫sculas. Por eso, para evitar errores, vamos a homogenizar el texto para que todo est√© en un solo formato: min√∫sculas.

Para ello crearemos un nuevo objeto: `diary_v_toks_lower` que albergar√° los valores del objeto del paso anterior, pero con la funci√≥n min√∫sculas aplicadas

```{r, eval=FALSE}
diary_v_toks_lower <- tokens_tolower(diary_v_toks)
```

#### PASO 3: eliminaci√≥n de los signos de puntuaci√≥n.

En nuestro texto, habr√° palabras que vengan unidas a un signo de puntuaci√≥n. Las comas, comillas y puntos pueden provocar que el programa identifica una misma palabra: `nalvany` y `nalvany.` como dos elementos distintos, lo que podr√≠a darnos un recuento distinto cuando hagamos b√∫squeda de patrones^\[4\]^.

Para realizar esta limpieza se har√° un nuevo objeto que llamaremos `nalvany_word_v`

```{r, eval=FALSE}
 nalvany_word_v <- tokens(diary_v_toks_lower, remove_punct = TRUE)
```

#### **ü§î¬øQu√© significa esta expresi√≥n?**

-   De nuevo el valor `nalvany_word_v` es un objeto al que se ha aplicado la funci√≥n `tokens`. Lo que le estamos diciendo a R es que el valor ya tokenizado `diary_v_toks_lower` vuelva a procesarlo tomando como par√°metro el valor `remove_punct=TRUE`

-   `remove_punct=TRUE` es el argumento que indica a `tokens()` que elimine toda la puntuaci√≥n del valor que le antecede, en este caso `diary_v_toks_lower`.

#### üîç Comprobaciones

Una vez hecho esta re-tokenizaci√≥n, vamos a crear un objeto que contenga la unidad total de valores que tiene el objeto `nalvany_word_v` . Esto nos ayudar√° a tener una idea total de la longitud del contenido, tambi√©n nos dar√° una idea de cu√°nto se ha reducido el texto al quitar caracteres y nos ahorrar√° tiempo para no tener que calcularlo cuando lo necesitemos

Aplicaremos la funci√≥n `ntoken` para averiguar la extensi√≥n total de nuestro texto.

```{r, eval=FALSE}
total_lenght <- ntoken(nalvany_word_v)
```

```         
text1 
 3697 #Nos tendr√≠a que devolver este valor
```

**¬øSab√≠as qu√©...?** Ô∏èü§ì‚òù

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[4\]~^ En ingl√©s, es posible que el texto venga acompa√±ado de ap√≥strofes como en los casos de `don't` y `he's`. Aqu√≠, `quanteda` no tomar√° las `'t` ni las `'s` como elementos aislados, sino que lo mantendr√° unida a la palabra para respetar el significado original.
:::

## ‚öôÔ∏è Las utilidades 

Ahora que tenemos todo nuestro texto listo para trabajar, podemos realizar operaciones sencillas, tales como:

-   **Comprobar cuantas veces se repite una palabra y su localizaci√≥n.**

Esto es especialmente util para realizar an√°lisis de frecuencia o de sentimientos al conocer el contexto donde se menciona esa palabra.

```{r, eval=FALSE}
which(nalvany_word_v[["text1"]] == "putin") |>
+     head()
```

```         
[1] 1735 2771
```

-   **Localizar una palabra exacta a trav√©s de su n√∫mero de caracter.**

Como sabemos el n√∫mero total de caracteres que tiene gracias a la funci√≥n `ntoken` podemos recuperar cualquier elemento con solo introducir un valor concreto

```{r, eval=FALSE}
nalvany_word_v[["text1"]][3666] 
```

```         
[1] "it"
```
