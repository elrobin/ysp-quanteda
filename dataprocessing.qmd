---
title: "Carga y procesamiento de textos"
format: html
toc: true   
toc-title: "칈ndice"       
toc-depth: 4              # Por alguna raz칩n no muestra t칤tulos de nivel 4. Revisarlo
code-copy: true
editor: visual
---

## 游닍Preparando los paquetes

Antes de comenzar el an치lisis es obligatorio instalar dos paquetes b치sicos: `quanteda` y `readtext` a trav칠s del comando: `install.packages(")` . En primer lugar, para poder instalar `quanteda` , as칤 como cualquier otro paquete en R, deberemos de de introducir en la consola el comando:

```{r, eval = FALSE}
install.packages("quanteda")
```

La misma f칩rmula aplicaremos para el paquete `readtext`

```{r, eval = FALSE}
install.packages("readtext")
```

#### 쯇or qu칠 lo usamos?

-   `quanteda` es la herramienta que nos va a proporcionar los recursos para hacer un an치lisis cuantitativo de un texto, incluyendo la tokenizaci칩n^\[1\]^, la creaci칩n de matrices de t칠rminos y el an치lisis de frecuencia.

-   `readtext` se utiliza para cargar y leer datos textuales desde diferentes formatos (como archivos de texto, documentos de Word, etc.). Para evitar dolores de cabeza, nosotros recomendamos que el material que se vaya a trabajar est칠 en un formato plano .txt. Los formatos anteriores pueden dar problemas por la forma en que se estructuran los datos y los elementos adicionales que suelen contener, lo que requiere aplicar procesos adicionales de limpieza que puede alargar nuestro an치lisis.

**쯉ab칤as qu칠...?** 勇游뱁驕

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[1\]~^ En `quanteda` hablamos de **tokenizaci칩n** para referirnos a la unidad m칤nima de trabajo.

Imaginate que tienes la siguiente oraci칩n:

"Hola, 쯖칩mo est치s?"

La tokenizaci칩n de esta frase podr칤a dar como resultado los siguientes tokens: "Hola", "", "c칩mo", "est치s", "?"

Esto es especialmente 칰til cuando estamos trabajando con estudios relacionados con frecuencias de palabras.
:::

## 游늯俱뫮잺游둰勇뀼olcando los archivos de texto a RStudio

Vamos a vincular el archivo de맚exto en la aplicaci칩n de RStudios. Para ello vamos a aplicar los dos paquetes que hemos instalado anteriormente맊on el comando `library("name")`

```{r, eval=FALSE}
library("quanteda")
library("readtext")
```

Es importante resaltar que, si no llamamos antes el paquete, los comandos que introduzcamos despu칠s no funcionar치n o nos dar치n error. Aseg칰rate de cargar siempre la librer칤a antes de empezar a trabajar.

Una vez cargados, el programa estar치 listo para leer nuestro archivo de texto. La formula que vamos a escribir para decirle a `quanteda` que archivo analizar ser치 el siguiente:

```{r, eval=FALSE}
data_char_NALVANY <- as.character(readtext::readtext("G:/Mi unidad/Yo sigo/NALVANY.txt"))
names(data_char_NALVANY) <- "NALVANY"
```

**仇듀TENICI칍N:** Si por alguna raz칩n hiciesemos alg칰n cambio en el contenido del archivo, deberemos de aplicar el paso anterior de nuevo. Cuando cargamos un archivo en R, se guarda una copia y cualquier cambio en el original no se refleja autom치ticamente.

#### 游뱂쯈u칠 significa esta funci칩n?

Vamos a desgranar este prompt para que pueda entenderse m치s facil:

-   `data_char_"TEXTO"`: La variable data_char_NALVANY es un objeto^\[2\]^ en R que almacena el texto como una cadena de caracteres (character vector).

-   `as.character()`: Convierte el objeto cargado en un formato de texto sencillo, que es m치s f치cil de manejar para el an치lisis.

-   `readtext::readtext`: Como v칠is, se ha utilizado una expresi칩n doble del paquete `readtext`. Esto proviene de la notaci칩n `paquete::funci칩n` y se hace cuando queremos asegurarnos de utilizar una funci칩n espec칤fica. Aqu칤, lo que le estamos diciendo a RStudios es que, del paquete `readtext`, aplique espec칤ficamente la funci칩n lectura que casualmente tambi칠n se llama `readtext`

    -   Un **problema muy com칰n** que puede surgir a la hora de introducir la URL de la ubicaci칩n del archivo es expresarlo con barras laterales izquierdas " \\ ", tal y como viene en la barra de direcci칩n del explorador de archivos de Windows, en vez de la derecha " / ". Si tienes problemas leer tu .txt 춰prueba con hacer este cambio!

-   `names(data_char_NALVANY) <- "Nalvany"`: Asigna un nombre al objeto que contiene el texto, facilitando su identificaci칩n en futuros an치lisis.

**쯉ab칤as qu칠...?** 勇游뱁驕

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[2\]~^ En `R` hablamos de **objetos** para referirnos a los contenedores donde almacenamos datos e informaci칩n. En el caso anterior, el objeto `data_char_NALVANY` almacena el texto plano que vamos a utilizar.

Existen distintos objetos con diferentes datos almacenados: matrices, n칰meros, listas jerarquizadas, as칤 como un sin fin de combinaciones. A lo largo de este caso pr치ctico trabajaremos con ellos para gestionar m치s facilmente el an치lisis cuantitativo.
:::

#### 游댌 Comprobaciones

En el an치lisis cuantitativo toda precauci칩n es poca , as칤 que vamos a realizar una serie de comprobaciones para verificar que el texto ha sido leido por el programa. Para ello, vamos a pedirle a RStudio que nos devuelva los primeros 75 caracteres de nuestro archivo NALVANY.txt mediante el paquete: `stringi`.

```{R, eval=FALSE}
library.("stringi") #Primero llamamos al paquete
stri_sub(data_char_NALVANY, 1, 75) #Aplicamos la funci칩n para que nos devuelva los caracteres situados entre la posici칩n 1 y 75.
```

Si hemos hecho los pasos bien, tendr칠is que haber recibir este texto de vuelta:

```         
[1] "2022\nJanuary 17th\nExactly one year ago today I came home, to Russia.\nI didn"
```

## 游듺勇뀨cotando nuestro espacio de trabajo

Nuestro siguiente objetivo es seleccionar qu칠 partes del texto vamos aplicar el an치lisis cuantitativo. Puede que nuestro foco de inter칠s sea algun apartado concreto de nuestro material, por lo que vamos a crear un objeto que albergue un rango determinado dentro de nuestro "".txt . Con esto nos quitaremos toda la informaci칩n innecesaria que puede ensuciar nuestros resultados.

El proceso que vamos a realizar a continuaci칩n es muy 칰til cuando los archivos que manejamos tienen ligados metadatos. Normalmente, esta metadata suele ser m치s un dolor de cabeza que otra cosa y es recomendable realizar una limpieza previa para que esos datos no se mezclen con el contenido de nuestro an치lisis.

En este apartado seguiremos trabajando con el paquete `stringi` ^\[3\]^

#### PASO 1: Asignaci칩n de los rangos del texto

Para crear el objeto que albergue el rango de texto a analizar deberemos empezar indicando donde empieza y termina nuestra selecci칩n. Para ello, crearemos dos valores de posici칩n: `start_v` y `end_v`, donde `start_` ser치: "2023, January 12th" y `end_v` "FIN".

Localizado el rango que queremos, la forma de expresarlo en el programa ser칤a el siguiente:

```{r, eval=FALSE}
(start_v <- stri_locate_first_fixed(data_char_NALVANY, "2023\nJanuary 12th")[1])
```

```{r, eval=FALSE}
(end_v <- stri_locate_last_fixed(data_char_NALVANY, "FIN")[1])
```

Si lo hemos aplicado bien, la funci칩n deber칤a de devolver los siguientes resultados

-   Para `start_value`

    ```         
    [1] 23653
    ```

<!-- -->

-   Para `end_value`

    ```         
    [1] 44141
    ```

#### 游뱂쯈u칠 significa esta expresi칩n?

-   Tanto `start_v` como `end_v` son nombres que hemos asignado a la posici칩n espec칤ficas del texto. En s칤, no significan nada. Solo decimos, a trav칠s de "\<- " que dichos nombres albergan una funci칩n de posicionamiento.

-   Las funciones del paquete `stringi`: `stri_locate_first_fixed` y `stri_locate_last_fixed` buscan y encuentran la primera coincidencia del valor entrecomillado que precede a nuestro objeto `data_char_NALVANY`

-   El \[1\] es un indicador que le estamos dando a la funci칩n para que escoja la primera posici칩n donde aparezca el texto que hayamos escogido.

-   As칤, cuando vemos devuelto las respuestas `[1] 23653` y `[1] 44141` quiere decir que para `start_v` y `end_v` est치 asignado el primer valor donde aparece dichas expresiones , localizadas por primera vez en la posici칩n 23653 y 44141 de nuestro texto.

#### PASO 2, creando nuestro objeto

Creado nuestro punto de inicio y final de nuestra zona de trabajo, haremos un objeto que alberge dicho rango. Lo llamaremos: `diary_v`

```{r, eval=FALSE}
diary_v <- stri_sub(data_char_NALVANY, start_v, end_v)
length(diary_v)
```

Al iniciar el c칩digo el valor que os ha tenido que recuperar, adem치s de almacenar el objeto en la pesta침a `Environment` de RStuido, es:

```         
[1] 1
```

#### 游뱂쯈u칠 significa esta expresi칩n?

-   `diary_v` es el nombre del objeto que almacena la funci칩n que ha sido asignada. En este caso, a trav칠s de `stri_sub`, estamos extrayendo una parte del texto `data_char_NALVANY` . A diferencia del caso anterior, aqu칤 le estamos pidiendo que, en vez de que recuper un n칰mero detemrinado de caracteres, escoja todos los que hay comprendidos entre las posiciones que hemos dado a `start_v` y a `end_v`. Con esto nos aseguramos que el objeto `diary_v` siempre trabaje en los rangos que nos interesa analizar.

-   `legth(diary_v)` es una expresi칩n que usamos para comprobar cuandos valores existen en nuestro objeto. Es una forma de asegurarnos de que nuestro objeto solo tiene un vector y no es un conjunto de fragmentos de texto. Por eso, al introducirlo, el programa nos devuelve el valor 1 porque solo hay 1 valor dentro de nuestro objeto.

**쯉ab칤as qu칠...?** 勇游뱁驕

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[3\]~^ El paquete `stringi` es una herramienta muy versatil para el manejo y procesamiento de cadenas de texto. Hemos visto como puede hacer b칰squedas de posicionamiento, pero tambi칠n puede servir para realizar operciones relacionadas con la manipulaci칩n de texto: ya sea para remplazar partes del mismo, verificar un formato o pasar de un c칩digo a otro.
:::

## 游 춰A la tokenizaci칩n!

Realizada la limpieza de datos, es hora de preparar nuestro material para convertirlo en un objeto analizable. Para ello haremos tres cosas:

1.  Convertiremos todo el texto almacenado en `diary_v` en tokens.
2.  Pasaremos toda la informaci칩n a min칰sculas mediante la funci칩n `tolower()`
3.  Eliminaremos los signos de puntuaci칩n con la funci칩n `remove_punct=TRUE`

#### PASO 1: tokenizaci칩n

Para que el programa pueda analizar y realizar manipulaciones sobre las palabras de forma individualizada, vamos a convertir a cada una de ellas en peque침os valores que llamamos **tokens.**

La funci칩n `tokens()` del paquete `quanteda` es el que nos ayudar치 a realizar este trabajo.

```{r, eval=FALSE}
diary_v_toks <- tokens(diary_v)
```

#### **游뱂쯈u칠 significa esta expresi칩n?**

Hemos creado un nuevo objeto: `diary_v_toks` donde los valores que tiene asignado han sido convertidos en una unidad manipulable llamado **token**. Esto nos permitir치 poder realizar los dos pasos siguientes.

#### PASO 2: eliminaci칩n de las may칰sculas.

R es sensible a las may칰sculas y las toma como valor diferente a como ser칤a en min칰sculas. Por eso, para evitar errores, vamos a homogenizar el texto para que todo est칠 en un solo formato: min칰sculas.

Para ello crearemos un nuevo objeto: `diary_v_toks_lower` que albergar치 los valores del objeto del paso anterior, pero con la funci칩n min칰sculas aplicadas

```{r, eval=FALSE}
diary_v_toks_lower <- tokens_tolower(diary_v_toks)
```

#### PASO 3: eliminaci칩n de los signos de puntuaci칩n.

En nuestro texto, habr치 palabras que vengan unidas a un signo de puntuaci칩n. Las comas, comillas y puntos pueden provocar que el programa identifica una misma palabra: `nalvany` y `nalvany.` como dos elementos distintos, lo que podr칤a darnos un recuento distinto cuando hagamos b칰squeda de patrones^\[4\]^.

Para realizar esta limpieza se har치 un nuevo objeto que llamaremos `nalvany_word_v`

```{r, eval=FALSE}
 nalvany_word_v <- tokens(diary_v_toks_lower, remove_punct = TRUE)
```

#### **游뱂쯈u칠 significa esta expresi칩n?**

-   De nuevo el valor `nalvany_word_v` es un objeto al que se ha aplicado la funci칩n `tokens`. Lo que le estamos diciendo a R es que el valor ya tokenizado `diary_v_toks_lower` vuelva a procesarlo tomando como par치metro el valor `remove_punct=TRUE`

-   `remove_punct=TRUE` es el argumento que indica a `tokens()` que elimine toda la puntuaci칩n del valor que le antecede, en este caso `diary_v_toks_lower`.

#### 游댌 Comprobaciones

Una vez hecho esta re-tokenizaci칩n, vamos a crear un objeto que contenga la unidad total de valores que tiene el objeto `nalvany_word_v` . Esto nos ayudar치 a tener una idea total de la longitud del contenido, tambi칠n nos dar치 una idea de cu치nto se ha reducido el texto al quitar caracteres y nos ahorrar치 tiempo para no tener que calcularlo cuando lo necesitemos

Aplicaremos la funci칩n `ntoken` para averiguar la extensi칩n total de nuestro texto.

```{r, eval=FALSE}
total_lenght <- ntoken(nalvany_word_v)
```

```         
text1 
 3697 #Nos tendr칤a que devolver este valor
```

**쯉ab칤as qu칠...?** 勇游뱁驕

::: {.tip style="background-color: #A8E6A1; border-left: 5px solid #A8E6A1; padding: 10px"}
^~\[4\]~^ En ingl칠s, es posible que el texto venga acompa침ado de ap칩strofes como en los casos de `don't` y `he's`. Aqu칤, `quanteda` no tomar치 las `'t` ni las `'s` como elementos aislados, sino que lo mantendr치 unida a la palabra para respetar el significado original.
:::

## 丘뙖잺 Las utilidades 

Ahora que tenemos todo nuestro texto listo para trabajar, podemos realizar operaciones sencillas, tales como:

-   **Comprobar cuantas veces se repite una palabra y su localizaci칩n.**

Esto es especialmente util para realizar an치lisis de frecuencia o de sentimientos al conocer el contexto donde se menciona esa palabra.

```{r, eval=FALSE}
which(nalvany_word_v[["text1"]] == "putin") |>
+     head()
```

```         
[1] 1735 2771
```

-   **Localizar una palabra exacta a trav칠s de su n칰mero de caracter.**

Como sabemos el n칰mero total de caracteres que tiene gracias a la funci칩n `ntoken` podemos recuperar cualquier elemento con solo introducir un valor concreto

```{r, eval=FALSE}
nalvany_word_v[["text1"]][3666] 
```

```         
[1] "it"
```
